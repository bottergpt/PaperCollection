ADualAugmentedTwo-towerModelforOnlineLarge-scale 
Recommendation 


YantaoYu,WeipengWang,ZhoutianFeng,DaiyueXue 
Meituan 
Beijing,China 
{yuyantao,wangweipeng02,fengzhoutian,xuedaiyue}@meituan.com 


ABSTRACT 


Manymodernrecommendersystemshaveaverylargecorpus,and 
acommonindustrialrecipeforhandlinglarge-scaleretrievalis 
tolearnqueryanditemrepresentationsfromtheircontentfeatureswiththetwo-
towermodel.However,themodelsuffersfrom 
lackofinformationinteractionbetweenthetwotowers.Besides, 
imbalancedcategorydataalsohindersthemodelperformance. 
Inthispaper,weproposeanovelmodelnamedDualAugmented 
Two-towerModel(DAT),whichintegratesanovelAdaptive-Mimic 
Mechanism(AMM)andaCategoryAlignmentLoss(CAL).Our 
AMMcustomizesanaugmentedvectorforeachqueryanditemto 
mitigatethelackofinformationinteraction.Moreover,ourCAL 
canfurtherimproveperformancebyaligningitemrepresentation 
ofunevencategories.Offlineexperimentsonlarge-scaledatasets 
areconductedtoshowthesuperiorperformanceofDAT.Moreover,
onlineA/BtestingsconfirmthatDATcanleadtoimproved 
recommendationqualityforindustrialapplications. 


CCSCONCEPTS 
â€¢Informationsystemsâ†’Recommendersystems;Information 
retrieval. 


KEYWORDS 


RecommenderSystems,InformationRetrieval,NeuralNetworks 


ACMReferenceFormat: 


YantaoYu,WeipengWang,ZhoutianFeng,DaiyueXue.2021.ADual 
AugmentedTwo-towerModelforOnlineLarge-scaleRecommendation. 
InProceedingsofDLP-KDD2021.ACM,NewYork,NY,USA,4pages.https: 
//doi.org/10.1145/1122445.1122456 


1 
INTRODUCTION 


Recommendersystemsareindispensableinfilteringoutitemsthat 
usersareinterestedinfromhugeamountsofitems.Oneofthe 
mostcrucialchallengesinlarge-scalerecommendationistoscore 
millionsorbillionsofitemsinreal-timeaccurately.Acommon 
practiceistodesigntherecommenderasatwo-phasearchitecture 
wherearetrievalmodelfirstretrievesasmallfractionofrelated 
itemsgivenuserâ€™squeryfromalargecorpus,andarankingmodel 


Permissiontomakedigitalorhardcopiesofallorpartofthisworkforpersonalor 
classroomuseisgrantedwithoutfeeprovidedthatcopiesarenotmadeordistributed 
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation 
onthefirstpage.CopyrightsforcomponentsofthisworkownedbyothersthanACM 
mustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish, 
topostonserversortoredistributetolists,requirespriorspecificpermissionand/ora 
fee.Requestpermissionsfrompermissions@acm.org. 


DLP-KDD2021,August15,2021,Singapore 


Â©2021AssociationforComputingMachinery. 
ACMISBN978-1-4503-XXXX-X/18/06...$15.00 
https://doi.org/10.1145/1122445.1122456 


rankstheretrieveditemsbasedonclicksoruser-ratings[2].Obviously,
thequalityofcandidatesretrievedintheretrievalstage 
playsacriticalroleinthewholesystem.Inthiswork,wefocuson 
theretrievalproblemwithanaimtoimprovetheretrievalsystemâ€™s 
performanceforpersonalizedrecommendationwithmillionsof 
queriesanditems. 


Ascalableretrievalmodelusuallylearnsqueryanditemrepresentationsfirstandthenusesacosinesimilaritybetweenthequery 
anditemrepresentationstoobtainrecommendationstailoredfor 
thequery.However,inindustrial-scaleapplications,thecorpusof 
itemscanbeenormouslylargeandthetrainingdatacollectedfrom 
usersâ€™feedbackislikelytobeverysparseformostqueriesand 
items,whichmayleadtoinaccuratemodelpredictionsforlong-tail 
usersanditems.Totackletheabovechallenges,thetwo-tower 
model[4],withtowersreferringtoencodersbasedondeepneural 
networks(DNNs),areusuallyapplied.Despitegreatpromise,there 
arestillsomeproblemsintwo-towermodel.Astheitemrepresentationoftheitemtowermustbepre-
computedseparatelyforonline 
retrievalservice,theforwardcomputationoftheitemtowermust 
beindependentwiththequerytower,andsothemodellacksinformationinteractionbetweenthetwotowers,
whichmayinevitably 
hinderthemodelâ€™sperformance.Inreal-worldapplications,the 
inputofonetowerhasapositiveinteractionwiththeinputofthe 
otherforeachclick.Forexample,supposethatitemğ´ 
isclicked 
inqueries{ğµ,ğ¶, 
ğ·}.Apparently,theinputsforthequerytower 
are{ğµ,ğ¶, 
ğ·},whichinteractwiththeinputğ´ 
oftheitemtower. 
Consequently,theinformationcontainedinthequerytowercan 
beleveragedtoaugmenttheitemrepresentationoftheitemtower, 
andviceversa.Furthermore,thecategoriesofitemsarediverse(e.g., 
food,hotels,movies,etc.)andtheamountofitemsineachcategory 
isimbalancedseverely.Thustheitemsinanindividualcategory 
mayaccountforthemajority.Consequently,modelperformsmuch 
worseonthecategorieswithrelativelysmalleramountofitems. 


Inthispaper,totackletheaboveissues,wepresentanovel 
retrievalmodelforlarge-scalerecommendationnamedDualAugmentedTwo-
towerModel(DAT).Specifically,wedesignanAdaptiveMimicMechanismtocustomizeanaugmentedvectorforeachquery 
anditemastheircontentfeatures.Theaugmentedvectorisupdated 
accordingtotheoutputrepresentationvectoroftheothertowerfor 
eachsamplewithpositivelabels.Inthisway,theaugmentedvector 
astheinputfeatureofonetowercarriesvaluableinformationofthe 
othertower,whichimplicitlymodelstheinformationinteraction 
betweenthetwotowers.AndwealsointroduceaCategoryAlignmentLossinthetrainingphasetoaligntherepresentationforitems 
fromdifferentcategories.Comprehensiveexperimentsshowthat 
ourDATfeatureshavetwomajoradvantages:i).itprovidesdeeper 
insightsintotheinformationinteractionoftwo-towermodelsin 



DLP-KDD2021,August15,2021,Singapore 
YantaoYu,WeipengWang,ZhoutianFeng,DaiyueXue 



Figure1:ThenetworkarchitectureofourproposedDualAugmentedTwo-towerModel 


theretrievaltask;ii).itproducesbetteritemrepresentationswhen 
thecategorydistributionisextremelyimbalanced. 


2 
MODELARCHITECTURE 


2.1 
ProblemStatement 
Weconsiderarecommendationsystemwithaqueryset{uğ‘– 
}ğ‘ 


ğ‘–=1

 
ğ‘€ 


andanitemset 
vğ‘— 
=1,whereğ‘ 
isthenumberofusersandğ‘€ 
is

ğ‘— 
thenumberofitems.Hereuğ‘– 
,vğ‘— 
aretheconcatenationsofvarious 
features(e.g.,IDsandcontentfeatures),whichcanbeveryhighdimensionalduetothesparsity.
Thequery-itemfeedbackcanbe 
representedbyamatrixğ‘… 
âˆˆRğ‘ 
Ã—ğ‘€ 
,whereğ‘…ğ‘– 
ğ‘— 
= 
1ifqueryğ‘– 
gives 
apositivefeedbackonitemğ‘—,andğ‘…ğ‘– 
ğ‘— 
= 
0otherwise.Ourobjective 
istoefficientlyselectpossiblythousandsofcandidateitemsfrom 
theentireitemcorpusgivenacertainquery. 


2.2 
DualAugmentedTwo-towerModel 
TheframeworkofourproposedmodelisillustratedinFigure1. 
TheDATmodelusesanaugmentedvectorağ‘¢ 
(ağ‘£)tocapturethe 
informationfromtheothertower,andregardsthevectorasthe 
inputfeatureofonetower.Additionally,theCategoryAlignment 
Losstransferstheknowledgelearnedinthecategorywiththe 
largestamountofdatatoothercategories 


2.2.1 
EmbeddingLayer.Similartotwo-towermodels,eachfeature 
fğ‘– 
âˆˆ 
R 
(e.g.,anitemID)inuğ‘– 
andvğ‘— 
goesthroughanembedding 
Rğ¾ 


layerandismappedtoalow-dimensionaldensevectoreğ‘– 
âˆˆ 
, 
whereğ¾ 
istheembeddingdimension.Specifically,wedefinean 
embeddingmatrixEâˆˆRğ¾Ã—ğ· 
whereEistobelearnedandğ· 
isthe 
numberofuniquefeatures,andtheembeddingvectoreğ‘– 
istheğ‘–th 
columnoftheembeddingmatrixE. 


2.2.2 
DualAugmentedlayer.Foracertainqueryandcandidate 
item,wecreatetwocorrespondingaugmentedvectorsağ‘¢ 
andağ‘£ 
by 
theirIDs,andconcatenatethemwithfeatureembeddingvectorsto 
obtaintheaugmentedinputvectorszğ‘¢ 
,zğ‘£ 
ofthetwotowers.For 
example,ifqueryğ‘¢ 
hasfeaturesâ€œuid=253,city=SH,gender=male,...â€ 
anditemğ‘£ 
hasfeaturesâ€œiid=149,price=10,class=cate,...â€,wehave: 
zğ‘¢ 
= 
[e253âˆ¥eğ‘ â„ 
âˆ¥eğ‘šğ‘ğ‘™ğ‘’ 
âˆ¥...âˆ¥ağ‘¢ 
] 


zğ‘£ 
= 
[e149 
eğ‘10 
eğ‘ğ‘ğ‘¡ğ‘’ 
âˆ¥...âˆ¥ağ‘£ 
] 


where|| 
isthevectorconcatenationoperation.Theaugmented 
inputvectorszğ‘¢ 
andzğ‘£ 
notonlycontaininformationaboutthecurrentqueryanditem,
butalsocontaininformationabouthistorical 
positiveinteractionsthroughağ‘¢ 
andağ‘£. 


Next,wefeedzğ‘¢ 
andzğ‘£ 
intothetwotowers,whicharecomposed 
offullyconnectedlayerswiththeReLUactivationfunction,inorder 
toachievetheinformationinteractionbetweenthetwotowersbyağ‘¢ 
andağ‘£ 
(augmentedvectors).Next,theoutputofthefullyconnected 
layersgoesthroughanL2normalizationlayertogetaugmented 
representationsofquerypğ‘¢ 
anditempğ‘£.Formally,thedefinition 
ofthetwostepsisasfollows: 


h1= 
ğ‘…ğ‘’ğ¿ğ‘ˆ 
(W1z+b1),... 
hğ¿ 
= 
ğ‘…ğ‘’ğ¿ğ‘ˆ 
(Wğ‘™ 
hğ¿âˆ’1+bğ‘™ 
), 
(1) 
p= 
ğ¿2ğ‘ğ‘œğ‘Ÿğ‘š 
(hğ¿ 
) 


wherezdenoteszğ‘¢ 
andzğ‘£,pdenotespğ‘¢ 
andpğ‘£ 
;Wğ‘™ 
andbğ‘™ 
arethe 
weightmatrixandbiasvectorfortheğ‘™ 
thlayer,respectively;pğ‘¢ 
andpğ‘£ 
,theoutputvectorsoftheL2normalizationlayer,represent 
thequeryembeddinganditemembedding,respectively.Thetwo 
towershavethesamestructurebutdifferentparameters. 


Furthermore,toestimatetheaugmentedvectorsağ‘¢ 
andağ‘£,we 
designanAdaptive-MimicMechanism(AMM),whichintegrates 
amimiclossandastopgradientstrategy.Themimiclossaimsto 
usetheaugmentedvectortofitallpositiveinteractionsintheother 
towerbelongingtothecorrespondingqueryoritem.Wedefine 
mimiclossasthemeansquareerrorbetweentheaugmentedvector 
andquery/itemembeddingpğ‘¢ 
,pğ‘£ 
foreachsampleofwhichlabel 
equalsto1: 


Ã•

1 


ğ‘™ğ‘œğ‘ ğ‘ ğ‘¢ 
= 
[ğ‘¦ağ‘¢ 
+(1âˆ’ğ‘¦)pğ‘£ 
âˆ’pğ‘£]2 


ğ‘‡ 


(ğ‘¢,ğ‘£,ğ‘¦)âˆˆT

Ã• 
(2)

1 


ğ‘™ğ‘œğ‘ ğ‘ ğ‘£ 
= 
[ğ‘¦ağ‘£ 
+(1âˆ’ğ‘¦)pğ‘¢ 
âˆ’pğ‘¢ 
]2 


ğ‘‡ 


(ğ‘¢,ğ‘£,ğ‘¦)âˆˆT 


whereğ‘‡ 
isthenumberofquery-itempairsinthetrainingdatasetT, 
andğ‘¦ 
âˆˆ{0, 
1}isthelabel.Wediscussthelabelingprocessinthenext 
sub-section.Ascanbeseen,ifthelabelğ‘¦ 
= 
1,ağ‘£ 
andağ‘¢ 
approach 
thequeryembeddingpğ‘¢ 
anditemembeddingpğ‘£;ifthelabelğ‘¦ 
= 
0, 



ADualAugmentedTwo-towerModelforOnlineLarge-scaleRecommendation 


thelossisisequalto0.AsshowninFigure1,theaugmentedvectors 
areusedinonetowerandthequery/itemembeddingsaregenerated 
fromtheother.Thatistosay,theaugmentedvectorsağ‘¢ 
andağ‘£ 
summarizethehigh-levelinformationaboutwhataqueryoran 
itempossiblymatchesfromtheothertower.Sincethemimicloss 
istoupdateağ‘¢ 
andağ‘£ 
,weshouldfreezethevalueofpğ‘¢ 
andpğ‘£ 
.To 
doso,thestopgradientstrategyisappliedtostopthegradientof 
ğ‘™ğ‘œğ‘ ğ‘ ğ‘¢ 
andğ‘™ğ‘œğ‘ ğ‘ ğ‘£ 
fromflowingbackintopğ‘£ 
andpğ‘¢ 
. 


Oncethetwoaugmentedvectorsağ‘¢ 
andağ‘£ 
areobtained,they 
areusedtomodeltheinformationinteractionbetweenthetwo 
towersbyregardingthemastheinputfeatureofthetwotowers. 
Finally,theoutputofthemodelistheinnerproductofthequery 
embeddinganditemembedding: 


ğ‘  
(u, 
v) 
= 
âŸ¨pğ‘¢, 
pğ‘£âŸ© 


whereğ‘  
(u, 
v)denotesthescoreprovidedbyourretrievalmodel. 


2.2.3 
CategoryAlignment.Intheindustrialscenario,thecategories 
ofitemswillbediverse(e.g.,food,hotels,movies,etc.)andthe 
numberofitemsineachcategoryisseriouslyuneven.Withthe 
imbalancedcategorydata,thetwo-towermodelperformsdifferentlyforthedifferentcategories,
anditperformsmuchworseon 
thecategorieswithrelativelysmalleramountofitems.Totackle 
theproblem,weproposeaCategoryAlignmentLoss(CAL)for 
trainingphase,whichtransferstheknowledgelearnedinthecategorieswithalargeamountofdatatoothercategories.
Specifically,
foreachbatch,theitemrepresentationpğ‘£ 
ofthecategory 
withthelargestamountofdataistakentoformthemajorcaten
o 


ğ‘šğ‘ğ‘—ğ‘œğ‘Ÿ 


goryset:ğ‘†ğ‘šğ‘ 
ğ‘—ğ‘œğ‘Ÿ 


= 
p 
,andthepğ‘£ 
ofothercategoriesform 


ğ‘£ 


theirrespectivecategorysets:ğ‘†2, 
ğ‘†3, 
ğ‘†4 
, 
....Wedefinethecategory 
alignmentlossasthedistancebetweenthesecond-orderstatistics 
(covariances)ofthemajorcategoryandothercategoriesfeatures: 


ğ‘›

Ã• 


2

ğ‘™ğ‘œğ‘ ğ‘ ğ¶ğ´ 
= 
C(ğ‘†ğ‘šğ‘ğ‘—ğ‘œğ‘Ÿ 
)âˆ’C(ğ‘†ğ‘– 
) 
(3)

ğ¹ 
ğ‘–=2 


whereâˆ¥Â·âˆ¥2denotesthesquaredmatrixFrobeniusnormandğ‘› 
is

ğ¹

thenumberofcategories.C(Â·)representsthecovariancematrix. 


2.3 
ModelTraining 
Wetreattheretrievalproblemasabinaryclassificationproblem,and 
employarandomnegativesamplingframework.Specifically,for 
thequeryineachpositivequery-itempair(label=1),werandomly 
sampleğ‘† 
itemsfromtheitemcorpustocreateğ‘† 
negativequeryitempairs(
label=0)withthisquery,andaddtheseğ‘† 
+1pairsto 
thetrainingdataset.Thecross-entropylossforthesepairsisas 
follows: 


Ã•

1 


ğ‘™ğ‘œğ‘ ğ‘ ğ‘ 
= 
âˆ’(ğ‘¦ğ‘™ğ‘œğ‘”ğœ 
(âŸ¨pğ‘¢, 
pğ‘£âŸ©)+(1âˆ’ğ‘¦)ğ‘™ğ‘œğ‘” 
(1âˆ’ğœ 
(âŸ¨pğ‘¢, 
pğ‘£ 
âŸ©))) 


ğ‘‡ 


(ğ‘¢,ğ‘£,ğ‘¦)âˆˆT 


ğ‘‡ 
= 
ğ· 
Ã—(ğ‘† 
+1) 


(4) 
whereğ· 
isthenumberofpositivefeedbackquery-itempairsandğ‘‡ 
isthetotalnumberoftrainpairs.ğœ 
(Â·)denotesthesigmoidfunction. 


Thefinallossfunctionisformulatedas: 


ğ‘™ğ‘œğ‘ ğ‘  
= 
ğ‘™ğ‘œğ‘ ğ‘ ğ‘ 
+ğœ†1ğ‘™ğ‘œğ‘ ğ‘ ğ‘¢ 
+ğœ†2ğ‘™ğ‘œğ‘ ğ‘ ğ‘£ 
+ğœ†3ğ‘™ğ‘œğ‘ ğ‘ ğ¶ğ´ 
(5) 


whereğœ†1, 
ğœ†2, 
ğœ†3aretunableparameters. 


DLP-KDD2021,August15,2021,Singapore 


Table1:StatisticsofDatasets. 


Dataset 
#users 
#items 
#interactions 
#categories 


AmazonBooks 
695,513 
243,166 
6,706,125 
11 
Meituan 
82,347,274 
3,561,498 
1,182,652,197 
9 


3 
EXPERIMENTS 


Inthissection,weconductedextensiveonlineandofflineexperimentstojustifytherationalityofDATâ€™sdesign. 


3.1 
Datasets 
Allmodelswereevaluatedontwoofflinelarge-scaledatasets:a 
largedatasetsampledfromthedailylogsofonlinesystemson 
Meituan1andadatasetfromAmazon[3].TheMeituandataset 
containsdatawithin11consecutivedaysinwhichthedataofthe 
first10dayswasfortrainingandthedataofthe11ğ‘¡â„ 
daywasfor 
testingandwecombinedalltheitemsthatappearedinthefirst10 
daysastheitemcorpus.TheAmazonBooksisrelativelysmaller, 
andweonlykeptitemsthathavebeenreviewedforleast5times 
anduserswhohavereviewedatleast5items.Weleftthelastitem 
outfortesting.Thedetailsofthetwoofflinedatasetsarelistedin 
Table1. 


3.2 
ExperimentalSetup 
Thefollowingmethodswhichwerewidelyappliedtoindustrial 
wereusedinthecomparisonwiththeproposedDATmodel: 
â€¢ 
WALS[1]Amatrixfactorizationalgorithmfordecomposing 
theinteractionmatrixintohiddenfactorsofusersanditems. 


â€¢ 
YouTubeDNN[2]Adeepneuralnetworkbasedrecommen


dationapproachthatfedvectorsintoamulti-layerfeedfor


wardneuralnetwork. 


â€¢ 
FM[7]Amodelthataccumulatesthefeaturevectorsof 


queryanditemandfeedsthemintotheFMlayer. 


â€¢ 
Two-towerModel[4]Apopularmodelinretrievaltaskand 


hasbeenwidelyintroducedtoleveragerichcontentfeature. 


â€¢ 
MIND[6]Arecentstate-of-the-artmodelforindustrialre


trievaltask.Thenumberofuserinterestsissetto4and5for 


theMeituandatasetandtheAmazondataset,respectively. 


WeimplementedthesemodelsbydistributedTensorFlowandused 
Faiss[5]toretrievethetop-Nitemsfromthelarge-scaleitempool. 
Theembeddingdimensionandbatchsizewerefixedto32and256 
forallmodels.AllmodelsweretrainedbytheAdamoptimizer. 
Toensureafaircomparison,otherhyperparametersofallmodels 
wereindividuallytunedtoachieveoptimalresults.ForDAT,the 
numberofFClayersineachtowerwasfixedto3,withdimensions 
256,128and32,respectively.Thedimensionsofaugmentedvectors 
ağ‘¢ 
andağ‘£ 
werebothsettoğ‘‘ 
= 
32whileğœ†1, 
ğœ†2weresetto0.5and 
ğœ†3wasset1.Toevaluatetheofflineeffectivenessofthevarious 
models,weemployedHitRate@KandMRRmetrics,whichwere 
widelyusedinindustrialretrieval.Kwassetto50and100asthe 
retrievalmodulewasrequiredtoretrievearelativelylargenumber 
ofcandidateitemstofeedtherankingmodule.Duetothelarge 
scaleoftestinginstances,weemployedascaledversionoftheMRR 
byafactorof10. 


1https://www.meituan.com/ 



DLP-KDD2021,August15,2021,Singapore 


Table2:PerformanceComparisonontwodatasetsinterms 
ofHitRateandMRR(w/oisshortforwithout). 


Meituan 
Amazon

Models 


HR@50HR@100 
MRR 
HR@50HR@100 
MRR 


WLAS 
0.2917 
0.4146 
0.3375 
0.0242 
0.0359 
0.0351 
FM 
0.4831 
0.6672 
0.5012 
0.0406 
0.0634 
0.0589 
YouTubeDNN 
0.4228 
0.5142 
0.4512 
0.0378 
0.0599 
0.0524 
Two-tower 
0.5395 
0.7159 
0.5472 
0.0464 
0.0732 
0.0625 
MIND 
0.5507* 
0.7327* 
0.5843* 
0.0490* 
0.0784* 
0.0673* 


DAT 
0.5796 
0.7682 
0.6154 
0.0519 
0.0836 
0.0711 
DAT(w/oCAL) 
0.5655 
0.7512 
0.6009 
0.0503 
0.0816 
0.0698 


3.3 
OfflineResults 
3.3.1 
ModelComparison.TheexperimentalresultsofDATand 
baselinesontwodatasetsarereportedinTable2.Thebestresults 
arelistedinbold,andthebestresultsofbaselinearemarkedwith 
star(*).Clearly,DAToutperformedallbaselinemodelsimproving 
HitRate@100by4.84%and6.63%ontwodatasetsoverthebest 
baseline.ThisdemonstratestheeffectivenessofDATandfurther 
justifiestheimportanceoftheAdaptive-MimicMechanism(AMM) 
andtheCategoryAlignmentLoss(CAL).WALS,thematrixfactorizationapproach,
receivedpoorperformancecomparedwith 
othermethods,confirmingtheeffectivenessofdeeplearningin 
theretrievalstageofrecommendersystems.Theimprovement 
obtainedbyFMcomparedwithYouTubeDNNhighlightstheadvantageoffeatureinteraction.
Moreover,withthehelpofdeep 
learning,thetwo-towermodelperformedmuchbetterthanFM 
andYouTubeDNN,whichcanbeexplainedbythefactthatitcan 
learnqueryanditemrepresentationsfrommorevaluablecontent 
features.Furthermore,consideringthatuserhasmultipleinterests, 
MINDperformsbetterthanthetwo-towermodel.Finally,theadvantageofDAT(
w/oCAL)overMINDandthetwo-towermodel 
andcanbeattributedtotheAMMthatcanexploittheinformation 
interactionbetweenthetwotowers. 
3.3.2 
DimensionofAugmentedVectors.Theaugmentedvectorin 
DATplaysapivotalroleinmodelingthetheinformationinteraction,
toanalyzetheimpactofthedimension,weinvestigatedthe 
performanceofDATonthetwodatasetswithrespecttothedimensionsofaugmentedvectors.
AsFigure2shows,theperformanceof 
DATonMeituanimprovedwiththeincreaseofdimensionwhile 
theperformanceofDATonAmazonimprovedinthefirstplaceand 
thendowngradedsubsequently.Thisiscausedbythedifferencein 
theamountofdatabetweenthetwodatasets.Inaddition,regardless 
ofthedimensionality,itcanalwaysachievebetterperformance, 
whichjustifytheeffectivenessoftheaugmentedvector. 
3.4 
OnlineExperiments 
Inadditiontoofflinestudies,weconductedonlineexperimentsby 
deployingDATtohandletherealtrafficforoneweekinarecommendersystemwhichserves60millionusersperday.
Tomake 
afaircomparison,theretrievalstagewasfollowedbythesame 
rankingprocedure.CTRandGMV,twowidelyusedindustrialmetrics,
wereusedtomeasuretheperformanceofmodelsforserving 
onlinetraffic.Thebaselinemethodforonlineexperimentswasthe 
two-towermodel,whichwasthebaseretrievalalgorithmserving 


YantaoYu,WeipengWang,ZhoutianFeng,DaiyueXue 



Figure2:PerformanceintermsofHR@100andMRRw.r.t 
thedimensionsofaugmentedvectorsonthetwodatasets. 



Figure3:OnlineperformanceofDATandbaselines 


themajorityoftheonlinetraffic.Therewereonehundredcandidateitemsretrievedbyeachmethodandfedtotherankingstage. 
Figure3showstheonlineresultsin7successivedays.Ourmodel 
outperformedthebaselinewithalargemargin,withanoverall 
averageimprovementsof4.17%and3.46%intermsofCTRand 
GMV,respectively. 


4 
CONCLUSION 


Inthispaper,wepresentaneffectiveretrievalmodelnamedDual 
AugmentedTwo-towerModel(DAT)forindustrialrecommendation 
systems.Itaimstomodeltheinformationinteractionbetweenthe 
twotowersandproducesbetteritemrepresentationsforimbalanced 
categorydata.Extensiveexperimentsonofflineandonlinedatasets 
showthattheDATmodel,withAMMandCAL,caneffectively 
achievesuperiorperformance. 


REFERENCES 


[1]ChristopherRAberger.2014.Recommender:Ananalysisofcollaborativefiltering 
techniques.PersonalandUbiquitousComputingJournal(2014). 


[2]PaulCovington,JayAdams,andEmreSargin.2016.Deepneuralnetworksfor 
youtuberecommendations.InProceedingsofthe10thACMconferenceonrecommendersystems.
191â€“198. 


[3]RuiningHeandJulianMcAuley.2016.Upsanddowns:Modelingthevisual 
evolutionoffashiontrendswithone-classcollaborativefiltering.Inproceedingsof 
the25thinternationalconferenceonworldwideweb.507â€“517. 
[4]Po-SenHuang,XiaodongHe,JianfengGao,LiDeng,AlexAcero,andLarryHeck. 
2013.Learningdeepstructuredsemanticmodelsforwebsearchusingclickthrough 
data.InProceedingsofthe22ndACMinternationalconferenceonInformation& 
KnowledgeManagement.2333â€“2338. 


[5]JeffJohnson,MatthijsDouze,andHervÃ©JÃ©gou.2017.Billion-scalesimilaritysearch 
withGPUs.arXivpreprintarXiv:1702.08734(2017). 


[6]ChaoLi,ZhiyuanLiu,MengmengWu,YuchiXu,HuanZhao,PipeiHuang,GuoliangKang,
QiweiChen,WeiLi,andDikLunLee.2019.Multi-interestnetwork 
withdynamicroutingforrecommendationatTmall.InProceedingsofthe28thACM 
InternationalConferenceonInformationandKnowledgeManagement.2615â€“2623. 


[7]SteffenRendle.2010.FactorizationMachines.InICDM2010,The10thIEEEInternationalConferenceonDataMining,
Sydney,Australia,14-17December2010. 



